{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1 - Python Code and Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# load training data\n",
    "digit_training_data = pd.read_csv('train.csv')\n",
    "\n",
    "# show first rows of the data\n",
    "digit_training_data.head(100)\n",
    "# show number of columns and rows\n",
    "digit_training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigation of Missing Data and Outliers in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find null counts, percentage of null values, and column type\n",
    "null_count = digit_training_data.isnull().sum()\n",
    "null_percentage = digit_training_data.isnull().sum() * 100 / len(digit_training_data)\n",
    "column_type = digit_training_data.dtypes\n",
    "\n",
    "# show null counts, percentage of null values, and column type for columns with more than one Null value\n",
    "null_summary = pd.concat([null_count, null_percentage, column_type], axis=1, keys=['Missing Count', 'Percentage Missing','Column Type'])\n",
    "null_summary_only_missing = null_summary[null_count != 0].sort_values('Percentage Missing',ascending=False)\n",
    "null_summary_only_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis displays that there is no missing data in the digit recognizer training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test dataset\n",
    "digit_testing_data = pd.read_csv('test.csv')\n",
    "\n",
    "# show first ten rows of the data\n",
    "digit_testing_data.head(10)\n",
    "# show number of columns and rows\n",
    "digit_testing_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigation of Missing Data and Outliers in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find null counts, percentage of null values, and column type\n",
    "null_count = digit_testing_data.isnull().sum()\n",
    "null_percentage = digit_testing_data.isnull().sum() * 100 / len(digit_training_data)\n",
    "column_type = digit_testing_data.dtypes\n",
    "\n",
    "# show null counts, percentage of null values, and column type for columns with more than one Null value\n",
    "null_summary = pd.concat([null_count, null_percentage, column_type], axis=1, keys=['Missing Count', 'Percentage Missing','Column Type'])\n",
    "null_summary_only_missing = null_summary[null_count != 0].sort_values('Percentage Missing',ascending=False)\n",
    "null_summary_only_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis displays that there is no missing data in the digit recognizer test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Principal Components Analysis (PCA) to Combined Training and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will combine the training and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the training dataframe\n",
    "pca_train_df = digit_training_data.copy(deep=True)\n",
    "\n",
    "# Drop the label column from the copy of the training dataframe\n",
    "pca_train_df.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "# Concatenate the training and test dataframes\n",
    "pca_df = pd.concat([pca_train_df, digit_testing_data])\n",
    "\n",
    "# show first rows of the data\n",
    "pca_df.head(10)\n",
    "# show number of columns and rows\n",
    "pca_df.shape\n",
    "# Describe the dataframe\n",
    "pca_df.describe()\n",
    "\n",
    "\n",
    "# find null counts, percentage of null values, and column type\n",
    "null_count = pca_df.isnull().sum()\n",
    "null_percentage = pca_df.isnull().sum() * 100 / len(digit_training_data)\n",
    "column_type = pca_df.dtypes\n",
    "\n",
    "# show null counts, percentage of null values, and column type for columns with more than one Null value\n",
    "null_summary = pd.concat([null_count, null_percentage, column_type], axis=1, keys=['Missing Count', 'Percentage Missing','Column Type'])\n",
    "null_summary_only_missing = null_summary[null_count != 0].sort_values('Percentage Missing',ascending=False)\n",
    "null_summary_only_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we scale the data to prepare it for our principal components analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale PCA dataframe's data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "pca_scaled = sc.fit_transform(pca_df) # normalizing the features\n",
    "\n",
    "# Convert scaled data from numpy array into dataframe\n",
    "pca_features = list(pca_df.columns.values)\n",
    "pca_scaled_df = pd.DataFrame(pca_scaled, columns=pca_features)\n",
    "\n",
    "# Confirm scaling transformation was a success\n",
    "pca_scaled_df.shape\n",
    "pca_scaled_df.head(10)\n",
    "pca_scaled_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also apply this scaling to our test dataframe for later use as we progress through the construction of our Principal Component Analysis and Random Forest model creation processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the standard scaling to the test dataframe\n",
    "pca_test_scaled = sc.transform(digit_testing_data)\n",
    "\n",
    "# Convert scaled data from numpy array into dataframe\n",
    "pca_test_features = list(digit_testing_data.columns.values)\n",
    "pca_test_scaled_df = pd.DataFrame(pca_test_scaled, columns=pca_test_features)\n",
    "\n",
    "# Confirm scaling transformation was a success\n",
    "pca_test_scaled_df.shape\n",
    "pca_test_scaled_df.head(10)\n",
    "pca_test_scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will conduct a Principal Components Analysis to identify principal components that account for at least 95% of the variation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer for the Principal Components Analysis\n",
    "import datetime\n",
    "pca_start = datetime.datetime.now()\n",
    "\n",
    "# Applying PCA function on training and testing set of X component\n",
    "from sklearn.decomposition import PCA\n",
    "pca_digits_train_test = PCA(n_components=334)\n",
    "principal_components_digits = pca_digits_train_test.fit_transform(pca_scaled_df)\n",
    "\n",
    "\n",
    "# Create a Cumulative Scree plot to help us determine how many principal components to include in our random forest model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PC_values = np.arange(pca_digits_train_test.n_components_) + 1\n",
    "cumulative_explained_variance_pca = np.cumsum(pca_digits_train_test.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(PC_values, cumulative_explained_variance_pca, 'o-', linewidth=1, color='blue')\n",
    "plt.title('Cumulative Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Cumulative Variance Explained')\n",
    "plt.show()\n",
    "\n",
    "# Create a dataframe to display the information in the cumulative scree plot in a different manner\n",
    "scree_df = pd.DataFrame({'Principal Component':PC_values, 'Variance Explained':cumulative_explained_variance_pca})\n",
    "scree_df\n",
    "\n",
    "# Create a dataframe that contains the principal component values for each of the observations in the pca dataframe\n",
    "pca_column_list = []\n",
    "for num in range(1, 335):\n",
    "    pca_column_list.append(\"PC_\" + str(num))\n",
    "\n",
    "pca_digits_df = pd.DataFrame(data = principal_components_digits , columns = pca_column_list )\n",
    "\n",
    "pca_digits_df\n",
    "\n",
    "\n",
    "# Print the run time for Python to complete the Principal Components Analysis\n",
    "pca_end = datetime.datetime.now()\n",
    "pca_runtime = pca_end - pca_start\n",
    "print(f\"The total run time for the Principal Components Analysis was {pca_runtime}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a Random Forest Model Using the Principal Components Identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a Random Forest Model to predict digits using the principal components just identified.  We will use our training and validation datasets to conduct hyperparameter tuning to find the best hyperparameters for random forest modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer for the Random Forest\n",
    "\n",
    "pca_rf_start = datetime.datetime.now()\n",
    "\n",
    "# Create the Random Forest Model\n",
    "\n",
    "# Import Required Modules\n",
    "#pip install graphviz\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# Split the training dataset into predictor and outcome components\n",
    "rf_train_validation_x = pca_digits_df.copy(deep=True)\n",
    "rf_train_validation_x.drop(rf_train_validation_x.tail(28000).index, inplace = True)\n",
    "rf_train_validation_y = digit_training_data['label']\n",
    "\n",
    "# Split the Kaggle training data into training and validation components\n",
    "rf_x_train, rf_x_validation, rf_y_train, rf_y_validation = train_test_split(rf_train_validation_x,\n",
    "                                                                      rf_train_validation_y, \n",
    "                                                                            test_size=0.2, \n",
    "                                                                           random_state = 1)\n",
    "\n",
    "# Conduct hyperparameter tuning for random forest models\n",
    "param_dist = {'n_estimators': randint(10,100),\n",
    "              'max_depth': randint(1,100),\n",
    "             'max_features': randint(1,20)}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "rand_search.fit(rf_x_train, rf_y_train)\n",
    "\n",
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "\n",
    "# Print the run time for Python to complete the Random Forest\n",
    "pca_rf_end = datetime.datetime.now()\n",
    "pca_rf_runtime = pca_rf_end - pca_rf_start\n",
    "print(f\"The total run time for the Random Forest Model using the principal components was {pca_rf_runtime}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will assess the strength of the random forest model associated with the optimal hyperparameters by applying the model to the validation dataset and observing the resulting confusion matrix and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions with the best model\n",
    "y_validation_predictions_rf = best_rf.predict(rf_x_validation)\n",
    "\n",
    "# Create the confusion matrix associated with the best random forest model\n",
    "cm = confusion_matrix(rf_y_validation, y_validation_predictions_rf)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
    "\n",
    "# Calculate the accuracy, precision, and recall associated with the predictions of the best random forest model\n",
    "\n",
    "accuracy_rf_validation = accuracy_score(rf_y_validation, y_validation_predictions_rf)\n",
    "#precision_rf_validation = precision_score(rf_y_validation, y_validation_predictions_rf)\n",
    "#recall_rf_validation = recall_score(rf_y_validation, y_validation_predictions_rf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_rf_validation)\n",
    "#print(\"Precision:\", precision_rf_validation)\n",
    "#print(\"Recall:\", recall_rf_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Random Forest Model to the Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for predictor variables in the test dataframe for random forest model\n",
    "#rf_testing_x = rf_testing_df.drop(columns=['PassengerId'])\n",
    "rf_testing_x = pca_digits_df.copy(deep=True)\n",
    "rf_testing_x.drop(rf_testing_x.head(42000).index, inplace = True)\n",
    "\n",
    "# Apply the Random Forest model to the test dataset\n",
    "y_test_predictions_rf = best_rf.predict(rf_testing_x)\n",
    "\n",
    "# Put the random forest predictions into a Pandas dataframe\n",
    "prediction_df_rf = pd.DataFrame(y_test_predictions_rf, columns=['Label'])\n",
    "\n",
    "# Add the ID column to the front of the random forest predictions dataframe\n",
    "ImageId_series = pd.Series(range(1,28001))\n",
    "prediction_df_rf.insert(0, 'ImageId', ImageId_series)\n",
    "\n",
    "#output predictions to csv\n",
    "#prediction_df_rf.to_csv('test_predictions_pca_random_forest_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the Kaggle results from the application of the random forest model using principal components to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the kaggle results associated with the Random Forest Model\n",
    "plt.figure(figsize = (15, 15))\n",
    "kaggle_results = plt.imread('Digit_PCA_Random_Forest_Kaggle_Results_v1.jpg')\n",
    "plt.imshow(kaggle_results)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a Random Forest Model Using the Principal Components Identified and the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a Random Forest Model to predict digits using the principal components and the original underlying data.  We will use our training and validation datasets to conduct hyperparameter tuning to find the best hyperparameters for random forest modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer for the Random Forest\n",
    "\n",
    "pca_rf_v2_start = datetime.datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "# Split the training dataset into predictor and outcome components\n",
    "rf_train_validation_x = pca_digits_df.copy(deep=True)\n",
    "rf_train_validation_x.drop(rf_train_validation_x.tail(28000).index, inplace = True)\n",
    "rf_train_validation_x = pd.concat([rf_train_validation_x, pca_train_df], axis=1)\n",
    "rf_train_validation_y = digit_training_data['label']\n",
    "\n",
    "# Split the Kaggle training data into training and validation components\n",
    "rf_x_train, rf_x_validation, rf_y_train, rf_y_validation = train_test_split(rf_train_validation_x,\n",
    "                                                                      rf_train_validation_y, \n",
    "                                                                            test_size=0.2, \n",
    "                                                                           random_state = 1)\n",
    "\n",
    "# Conduct hyperparameter tuning for random forest models\n",
    "param_dist = {'n_estimators': randint(10,100),\n",
    "              'max_depth': randint(1,100),\n",
    "             'max_features': randint(1,20)}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "rand_search.fit(rf_x_train, rf_y_train)\n",
    "\n",
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "\n",
    "\n",
    "# Print the run time for Python to complete the Random Forest\n",
    "pca_rf_v2_end = datetime.datetime.now()\n",
    "pca_rf_v2_runtime = pca_rf_v2_end - pca_rf_v2_start\n",
    "print(f\"The total run time for the Random Forest Model using the principal components and original pixel features was {pca_rf_v2_runtime}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will assess the strength of the random forest model associated with the optimal hyperparameters by applying the model to the validation dataset and observing the resulting confusion matrix and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with the best model\n",
    "y_validation_predictions_rf = best_rf.predict(rf_x_validation)\n",
    "\n",
    "# Create the confusion matrix associated with the best random forest model\n",
    "cm = confusion_matrix(rf_y_validation, y_validation_predictions_rf)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
    "\n",
    "# Calculate the accuracy, precision, and recall associated with the predictions of the best random forest model\n",
    "\n",
    "accuracy_rf_validation = accuracy_score(rf_y_validation, y_validation_predictions_rf)\n",
    "#precision_rf_validation = precision_score(rf_y_validation, y_validation_predictions_rf)\n",
    "#recall_rf_validation = recall_score(rf_y_validation, y_validation_predictions_rf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_rf_validation)\n",
    "#print(\"Precision:\", precision_rf_validation)\n",
    "#print(\"Recall:\", recall_rf_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Random Forest Model to the Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for predictor variables in the test dataframe for random forest model\n",
    "rf_testing_x = pca_digits_df.copy(deep=True)\n",
    "rf_testing_x.drop(rf_testing_x.head(42000).index, inplace = True)\n",
    "rf_testing_x.reset_index(drop=True, inplace=True)\n",
    "digit_testing_data.reset_index(drop=True, inplace=True)\n",
    "rf_testing_x = pd.concat([rf_testing_x, digit_testing_data], axis=1)\n",
    "\n",
    "# Apply the Random Forest model to the test dataset\n",
    "y_test_predictions_rf = best_rf.predict(rf_testing_x)\n",
    "\n",
    "# Put the random forest predictions into a Pandas dataframe\n",
    "prediction_df_rf = pd.DataFrame(y_test_predictions_rf, columns=['Label'])\n",
    "\n",
    "# Add the ID column to the front of the random forest predictions dataframe\n",
    "ImageId_series = pd.Series(range(1,28001))\n",
    "prediction_df_rf.insert(0, 'ImageId', ImageId_series)\n",
    "\n",
    "#output predictions to csv\n",
    "#prediction_df_rf.to_csv('test_predictions_pca_random_forest_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the Kaggle results from the application of the random forest model using principal components and the original underlying data features to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the kaggle results associated with the Random Forest Model\n",
    "plt.figure(figsize = (15, 15))\n",
    "kaggle_results = plt.imread('Digit_PCA_And_Original_Features_Random_Forest_Kaggle_Results_v1.jpg')\n",
    "plt.imshow(kaggle_results)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitigate design flaw\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sc = StandardScaler()\n",
    "train = digit_training_data.drop(columns = 'label')\n",
    "train_label = digit_training_data['label']\n",
    "scaled_train = sc.fit_transform(train)\n",
    "\n",
    "pca = PCA(n_components=334)\n",
    "pca_train = pca.fit_transform(scaled_train)\n",
    "\n",
    "# Split the Kaggle training data into training and validation components\n",
    "rf_x_train, rf_x_validation, rf_y_train, rf_y_validation = train_test_split(pca_train, train_label, test_size=0.2, random_state = 1)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(rf_x_train, rf_y_train)\n",
    "predictions = rf.predict(rf_x_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use K-means clustering to predict digits using original features. First let's create our training and testing data and plot the digits in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Split the training dataset into predictor and outcome variables\n",
    "kmeans_x_train = digit_training_data.copy(deep=True)\n",
    "kmeans_x_train.drop(['label'], axis=1, inplace=True)\n",
    "kmeans_y_train = digit_training_data['label']\n",
    "\n",
    "\n",
    "kmeans_x_train = np.array(kmeans_x_train)\n",
    "kmeans_y_train = np.array(kmeans_y_train)\n",
    "\n",
    "\n",
    "print('Training Data: {}'.format(kmeans_x_train.shape))\n",
    "print('Training Labels: {}'.format(kmeans_y_train.shape))\n",
    "\n",
    "# reshape array to 3-dimensional array so we can plot the numbers\n",
    "kmeans_x_train_plot = kmeans_x_train.reshape(42000, 28, 28)\n",
    "\n",
    "# Plot the digits in the dataset\n",
    "fig, axs = plt.subplots(3, 3, figsize = (12, 12))\n",
    "plt.gray()\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.matshow(kmeans_x_train_plot[i])\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Number {}'.format(kmeans_y_train[i]))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the training data before applying k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "kmeans_x_train_norm = preprocessing.normalize(kmeans_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset contains images of the integers 0 to 9. Because of this, let’s start by setting the number of clusters to 10, one for each digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the silhouette coefficients kmeans models with different numbers of clusters. This can vary between –1 and +1. A coefficient close to +1 means that the instance is well inside its own cluster and far from other clusters, while a coefficient close to 0 means that it is close to a cluster boundary; finally, a coefficient close to –1 means that the instance may have been assigned to the wrong cluster.\n",
    "\n",
    "reference: Geron, Aurelien. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. 2nd ed. Sebastopol, CA: O'Reilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "# minibatchkmeans has a memory leak warning that we can ignore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# create k-means models with K clusters. \n",
    "K = clusters=[10,16,36,64,144,256,400] # test listed cluster numbers\n",
    "\n",
    "# Store within-cluster-sum of squares and silhouette scores for clusters\n",
    "wss = []\n",
    "sil_score = []\n",
    "\n",
    "# loop though cluster values and save inertia and silhouttee values\n",
    "for i in K:\n",
    "    kmeans=MiniBatchKMeans(n_clusters=i, random_state=1)\n",
    "    kmeans=kmeans.fit(kmeans_x_train_norm)\n",
    "    # within-cluster-sum-squares\n",
    "    wss_iter = kmeans.inertia_\n",
    "    wss.append(wss_iter)\n",
    "    # silhouttee score\n",
    "    score = silhouette_score(kmeans_x_train_norm, kmeans.labels_)\n",
    "    sil_score.append(score)\n",
    "    print (\"Silhouette score for k(clusters) = \"+str(i)+\" is \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# elbow and silhouttee scores in dataframe with number of clusters\n",
    "cluster_sil_scores = pd.DataFrame({'Clusters' : K, 'WSS' : wss, 'Sil Score' : sil_score})\n",
    "cluster_sil_scores\n",
    "\n",
    "# plot the elbow scores\n",
    "sns.lineplot(x = 'Clusters', y = 'WSS', data = cluster_sil_scores, marker=\"+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the elbow plot, the inertia drops very quickly as we increase k up to 50, but then it decreases a bit more slowly as we keep increasing k. This curve has a distinct elbow shape, we also a more gradual decline around 250.\n",
    "\n",
    "This indicates that 144 and 256 could be optimal cluster numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the silhouttee scores\n",
    "sns.lineplot(x = 'Clusters', y = 'Sil Score', data = cluster_sil_scores, marker=\"+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot, silhouette scores decline as the number of clusters increases. Scores close to 0 suggest that the clusters are overlapping, and the model with more clusters may not able to distinguish them well.\n",
    "\n",
    "This isn't what we observe with the inertia plot, so we will still test models with 144 and 256 clusters. We also know there are 10 digits that are represented in the dataset so this could also be an optimal cluster number. We will build three models using  these cluster numbers and compare performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is an unsupervised machine learning method so the labels assigned by our KMeans algorithm refer to the cluster each array was assigned to, not the actual target integer. This section defines functions that predict which integer corresponds to each cluster. reference: https://medium.datadriveninvestor.com/k-means-clustering-for-imagery-analysis-56c9976f16b6#:~:text=Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    inferred_labels = {}\n",
    "\n",
    "    for i in range(kmeans.n_clusters):\n",
    "\n",
    "        # find index of points in cluster\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "\n",
    "        # append actual labels for each point in cluster\n",
    "        labels.append(actual_labels[index])\n",
    "\n",
    "        # determine most common label\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "\n",
    "        # assign the cluster to a value in the inferred_labels dictionary\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            # append the new number to the existing array at this slot\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            # create a new array in this slot\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "\n",
    "        #print(labels)\n",
    "        #print('Cluster: {}, label: {}'.format(i, np.argmax(counts)))\n",
    "\n",
    "    return inferred_labels\n",
    "\n",
    "def infer_data_labels(X_labels, cluster_labels):\n",
    "  # empty array of len(X)\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
    "\n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build models with 10, 144, and 256 clusters based on our knowledge of the data and the elbow and silhouette plot analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "\n",
    "########### Initialize KMeans model with 10 clusters ##############\n",
    "# Initialize KMeans model\n",
    "kmeans = MiniBatchKMeans(n_clusters = 10, random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "kmeans.fit(kmeans_x_train_norm)\n",
    "\n",
    "# Predict the cluster assignment\n",
    "X_clusters = kmeans.predict(kmeans_x_train_norm)\n",
    "print(X_clusters[:20])\n",
    "\n",
    "# predict labels for kmeans model with 10 clusters\n",
    "cluster_labels=infer_cluster_labels(kmeans,kmeans_y_train)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "\n",
    "# print first 20 predicted labels and actual y-values\n",
    "print(predicted_labels[:20])\n",
    "print(kmeans_y_train[:20])\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(kmeans_y_train, predicted_labels)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
    "\n",
    "# Calculate the accuracy, inertia, and homogeneity scores\n",
    "accuracy_kmeans = accuracy_score(kmeans_y_train, predicted_labels)\n",
    "inertia_kmeans = kmeans.inertia_\n",
    "homogeneity_kmeans = metrics.homogeneity_score(kmeans_y_train,predicted_labels)\n",
    "print(\"Accuracy of K=10:\", accuracy_kmeans)\n",
    "print(\"Inertia of K=10:\", inertia_kmeans)\n",
    "print(\"Homogeneity of K=10:\", homogeneity_kmeans)\n",
    "\n",
    "########### Initialize KMeans model with 144 clusters ##############\n",
    "kmeans = MiniBatchKMeans(n_clusters = 144, random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "kmeans.fit(kmeans_x_train_norm)\n",
    "\n",
    "# Predict the cluster assignment\n",
    "X_clusters = kmeans.predict(kmeans_x_train_norm)\n",
    "print(X_clusters[:20])\n",
    "\n",
    "# predict labels for kmeans model with 144 clusters\n",
    "cluster_labels=infer_cluster_labels(kmeans,kmeans_y_train)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "\n",
    "# print first 20 predicted labels and actual y-values\n",
    "print(predicted_labels[:20])\n",
    "print(kmeans_y_train[:20])\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(kmeans_y_train, predicted_labels)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
    "\n",
    "# Calculate the accuracy scores\n",
    "accuracy_kmeans = accuracy_score(kmeans_y_train, predicted_labels)\n",
    "inertia_kmeans = kmeans.inertia_\n",
    "homogeneity_kmeans = metrics.homogeneity_score(kmeans_y_train,predicted_labels)\n",
    "print(\"Accuracy of K=144:\", accuracy_kmeans)\n",
    "print(\"Inertia of K=144:\", inertia_kmeans)\n",
    "print(\"Homogeneity of K=144:\", homogeneity_kmeans)\n",
    "\n",
    "\n",
    "########### Initialize KMeans model with 256 clusters ##############\n",
    "# Initialize KMeans model\n",
    "kmeans = MiniBatchKMeans(n_clusters = 256, random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "kmeans.fit(kmeans_x_train_norm)\n",
    "\n",
    "# Predict the cluster assignment\n",
    "X_clusters = kmeans.predict(kmeans_x_train_norm)\n",
    "print(X_clusters[:20])\n",
    "\n",
    "# predict labels for kmeans model with 256 clusters\n",
    "cluster_labels = infer_cluster_labels(kmeans,kmeans_y_train)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "\n",
    "# print first 20 predicted labels and actual y-values\n",
    "print(predicted_labels[:20])\n",
    "print(kmeans_y_train[:20])\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(kmeans_y_train, predicted_labels)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
    "\n",
    "# Calculate the accuracy scores\n",
    "accuracy_kmeans = accuracy_score(kmeans_y_train, predicted_labels)\n",
    "inertia_kmeans = kmeans.inertia_\n",
    "homogeneity_kmeans = metrics.homogeneity_score(kmeans_y_train,predicted_labels)\n",
    "print(\"Accuracy of K=256:\", accuracy_kmeans)\n",
    "print(\"Inertia of K=256:\", inertia_kmeans)\n",
    "print(\"Homogeneity of K=256:\", homogeneity_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe accuracy scores of \n",
    " - 0.594 for the k-means model with 10 clusters \n",
    " - 0.881 for the k-means model with 144 clusters\n",
    " - 0.921 for the k-means model with 256 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Cluster Centroids\n",
    "\n",
    "Let's display the most representative image for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KMeans model with 256 clusters\n",
    "kmeans = MiniBatchKMeans(n_clusters = 256, random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "kmeans.fit(kmeans_x_train_norm)\n",
    "\n",
    "# record centroid values\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# reshape centroids into images\n",
    "images = centroids.reshape(256, 28, 28)\n",
    "images *= 255\n",
    "images = images.astype(np.uint8)\n",
    "\n",
    "# determine cluster labels\n",
    "cluster_labels = infer_cluster_labels(kmeans, kmeans_y_train)\n",
    "\n",
    "# create figure with subplots using matplotlib.pyplot\n",
    "fig, axs = plt.subplots(32, 8, figsize = (20, 20))\n",
    "plt.gray();\n",
    "\n",
    "# loop through subplots and add centroid images\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    \n",
    "    # determine inferred label using cluster_labels dictionary\n",
    "    for key, value in cluster_labels.items():\n",
    "        if i in value:\n",
    "            ax.set_title('Inferred Label:{}'.format(key), fontsize=8)\n",
    "    \n",
    "    # add image to subplot\n",
    "    ax.matshow(images[i]);\n",
    "    ax.axis('off');\n",
    "    \n",
    "# display the figure\n",
    "fig.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the K-means Clustering Model to the Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for predictor variables in the test dataframe for kmeans model\n",
    "kmeans_testing_x = digit_testing_data.copy(deep=True)\n",
    "#kmeans_testing_x.drop(['Label'], axis=1, inplace=True)\n",
    "\n",
    "# Apply the kmeans model to the test dataset\n",
    "y_test_prediction_clusters_kmeans = kmeans.predict(kmeans_testing_x)\n",
    "\n",
    "# predict labels for kmeans model\n",
    "kmeans_predictions = infer_data_labels(y_test_prediction_clusters_kmeans, cluster_labels)\n",
    "\n",
    "# Put the kmeans predictions into a Pandas dataframe\n",
    "prediction_df_kmeans = pd.DataFrame(kmeans_predictions, columns=['Label'])\n",
    "\n",
    "# Add the ID column to the front of the kmeans predictions dataframe\n",
    "ImageId_series = pd.Series(range(1,28001))\n",
    "prediction_df_kmeans.insert(0, 'ImageId', ImageId_series)\n",
    "\n",
    "# Output predictions to csv\n",
    "#prediction_df_kmeans.to_csv('test_predictions_kmeans_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the Kaggle results from the application of the kmeans model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the kaggle results associated with the Random Forest Model\n",
    "plt.figure(figsize = (15, 15))\n",
    "kaggle_results = plt.imread('Digit_Kmeans_v1.jpg')\n",
    "plt.imshow(kaggle_results)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
